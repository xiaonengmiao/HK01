{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Question A. Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import os\n",
    "conn = sqlite3.connect('webvisit.sqlite')\n",
    "c = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    c.execute('CREATE TABLE webvisit_db (userid INTEGER, pageid INTEGER, visitime TEXT)')\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('junior-data-test.csv', 'rt') as csvfile:\n",
    "    dr = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
    "    for t in dr:\n",
    "        c.execute('INSERT INTO webvisit_db VALUES (?,?,?)', t)\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visits in the data set:\n",
      "357912\n"
     ]
    }
   ],
   "source": [
    "# Q.A How many visits are in the data set?\n",
    "conn = sqlite3.connect('webvisit.sqlite')\n",
    "c = conn.cursor()\n",
    "c.execute('SELECT COUNT(*) FROM webvisit_db')\n",
    "result = c.fetchall()\n",
    "conn.close()\n",
    "print('Visits in the data set:')\n",
    "print(result[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinct users are in the data set:\n",
      "64265\n"
     ]
    }
   ],
   "source": [
    "# Q.A How many distinct users are in the data set?\n",
    "conn = sqlite3.connect('webvisit.sqlite')\n",
    "c = conn.cursor()\n",
    "c.execute('SELECT COUNT(DISTINCT userid) FROM webvisit_db')\n",
    "result = c.fetchall()\n",
    "conn.close()\n",
    "print('Distinct users are in the data set:')\n",
    "print(result[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinct pages in the data set:\n",
      "15163\n"
     ]
    }
   ],
   "source": [
    "# Q.A How many distinct pages are in the data set?\n",
    "conn = sqlite3.connect('webvisit.sqlite')\n",
    "c = conn.cursor()\n",
    "c.execute('SELECT COUNT(DISTINCT pageid) FROM webvisit_db')\n",
    "result = c.fetchall()\n",
    "conn.close()\n",
    "print('Distinct pages in the data set:')\n",
    "print(result[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hour gives the smallest number of visits:\n",
      "04:00:00 - 04:59:59\n"
     ]
    }
   ],
   "source": [
    "# Q.A Which hour gives the smallest number of visits?\n",
    "conn = sqlite3.connect('webvisit.sqlite')\n",
    "c = conn.cursor()\n",
    "c.execute(\"\"\"SELECT a.hour, MIN(a.hour_cnt) AS min\"\"\"\\\n",
    "          \"\"\" FROM (SELECT strftime('%H', visitime) AS hour, COUNT(*) AS hour_cnt FROM webvisit_db GROUP BY 1) a\"\"\")\n",
    "result = c.fetchall()\n",
    "conn.close()\n",
    "print('Hour gives the smallest number of visits:')\n",
    "print('%s:00:00 - %s:59:59' % (result[0][0], result[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hour gives the smallest number of visits:\n",
      "12:00:00 - 12:59:59\n"
     ]
    }
   ],
   "source": [
    "# Q.A Which hour gives the largest number of visits?\n",
    "conn = sqlite3.connect('webvisit.sqlite')\n",
    "c = conn.cursor()\n",
    "c.execute(\"\"\"SELECT a.hour, MAX(a.hour_cnt)\"\"\"\\\n",
    "          \"\"\" FROM (SELECT strftime('%H', visitime) AS hour, COUNT(*) AS hour_cnt FROM webvisit_db GROUP BY 1) a\"\"\")\n",
    "result = c.fetchall()\n",
    "conn.close()\n",
    "print('Hour gives the smallest number of visits:')\n",
    "print('%s:00:00 - %s:59:59' % (result[0][0], result[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Largest number of visits in the data set and corresponding number of visits:\n",
      "(6819, 15163)\n"
     ]
    }
   ],
   "source": [
    "# Q.A Which page has the largest number of visits in the data set? What is the corresponding number of visits?\n",
    "conn = sqlite3.connect('webvisit.sqlite')\n",
    "c = conn.cursor()\n",
    "c.execute('SELECT pageid, MAX(DISTINCT(pageid)) FROM webvisit_db')\n",
    "result = c.fetchall()\n",
    "conn.close()\n",
    "print('Largest number of visits in the data set and corresponding number of visits:')\n",
    "print(result[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question B. Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am not familiar with visualization within a web browser. I know **D3.js** which is JavaScript might be proper in doing this task. Here is [link](https://d3js.org/#introduction). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question C. Data Science - Tagging prediction\n",
    "In fact, I used the traditional **logistic regression model** for this new classification since the task is quite simple. After loading the data from the csv file, the first important step is to clean the text data by stripping it of all unwanted characters, for example HTML markup or punctuation. Then I process the text into tokens with **jieba**. After that, I vectorizer the text using **HashingVectorizer** from *scikit-learn*. Having set up all the complementary functions, I can start to train the logistic regression model with stochastic gradient descent.\n",
    "\n",
    "Answers to the questions are at the end after code. The accuracy is around 99% in my test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv('./offsite-test-material/offsite-tagging-training-set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tags</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3889</th>\n",
       "      <td>26483</td>\n",
       "      <td>足球</td>\n",
       "      <td>【歐國盃．深宵福利】空手道索太食譜加愛心　成就金靴「羅拔仔」 有誰自認入得廚房，出得Gym房...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3890</th>\n",
       "      <td>3231</td>\n",
       "      <td>足球</td>\n",
       "      <td>阿士東維拉驚險過關　英足盃兩球淨勝乙組仔 今季走勢低迷的阿士東維拉，在英超榜尾苦苦掙扎，轉到...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3891</th>\n",
       "      <td>90791</td>\n",
       "      <td>足球</td>\n",
       "      <td>【港足日與夜．朱兆基】37歲唔認老不服輸　更要喚起南華霸氣 周日（5月14日）於足總盃再撼傑...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3892</th>\n",
       "      <td>56574</td>\n",
       "      <td>梁振英</td>\n",
       "      <td>【特首選戰】梁營啟動競選工程　三女將婉拒入連任辦 羅范工作困身　婉拒「歸隊」\\r\\r\\n\\r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3893</th>\n",
       "      <td>77253</td>\n",
       "      <td>足球</td>\n",
       "      <td>【英超】曼城撼利物浦求反底　效率王辛尼下半季爆發成關鍵 與阿古路一同下半季發力的，不是倒戈利...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id tags                                               text\n",
       "3889  26483   足球  【歐國盃．深宵福利】空手道索太食譜加愛心　成就金靴「羅拔仔」 有誰自認入得廚房，出得Gym房...\n",
       "3890   3231   足球  阿士東維拉驚險過關　英足盃兩球淨勝乙組仔 今季走勢低迷的阿士東維拉，在英超榜尾苦苦掙扎，轉到...\n",
       "3891  90791   足球  【港足日與夜．朱兆基】37歲唔認老不服輸　更要喚起南華霸氣 周日（5月14日）於足總盃再撼傑...\n",
       "3892  56574  梁振英  【特首選戰】梁營啟動競選工程　三女將婉拒入連任辦 羅范工作困身　婉拒「歸隊」\\r\\r\\n\\r...\n",
       "3893  77253   足球  【英超】曼城撼利物浦求反底　效率王辛尼下半季爆發成關鍵 與阿古路一同下半季發力的，不是倒戈利..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See some examples of data\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tags</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3889</th>\n",
       "      <td>26483</td>\n",
       "      <td>2</td>\n",
       "      <td>【歐國盃．深宵福利】空手道索太食譜加愛心　成就金靴「羅拔仔」 有誰自認入得廚房，出得Gym房...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3890</th>\n",
       "      <td>3231</td>\n",
       "      <td>2</td>\n",
       "      <td>阿士東維拉驚險過關　英足盃兩球淨勝乙組仔 今季走勢低迷的阿士東維拉，在英超榜尾苦苦掙扎，轉到...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3891</th>\n",
       "      <td>90791</td>\n",
       "      <td>2</td>\n",
       "      <td>【港足日與夜．朱兆基】37歲唔認老不服輸　更要喚起南華霸氣 周日（5月14日）於足總盃再撼傑...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3892</th>\n",
       "      <td>56574</td>\n",
       "      <td>0</td>\n",
       "      <td>【特首選戰】梁營啟動競選工程　三女將婉拒入連任辦 羅范工作困身　婉拒「歸隊」\\r\\r\\n\\r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3893</th>\n",
       "      <td>77253</td>\n",
       "      <td>2</td>\n",
       "      <td>【英超】曼城撼利物浦求反底　效率王辛尼下半季爆發成關鍵 與阿古路一同下半季發力的，不是倒戈利...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  tags                                               text\n",
       "3889  26483     2  【歐國盃．深宵福利】空手道索太食譜加愛心　成就金靴「羅拔仔」 有誰自認入得廚房，出得Gym房...\n",
       "3890   3231     2  阿士東維拉驚險過關　英足盃兩球淨勝乙組仔 今季走勢低迷的阿士東維拉，在英超榜尾苦苦掙扎，轉到...\n",
       "3891  90791     2  【港足日與夜．朱兆基】37歲唔認老不服輸　更要喚起南華霸氣 周日（5月14日）於足總盃再撼傑...\n",
       "3892  56574     0  【特首選戰】梁營啟動競選工程　三女將婉拒入連任辦 羅范工作困身　婉拒「歸隊」\\r\\r\\n\\r...\n",
       "3893  77253     2  【英超】曼城撼利物浦求反底　效率王辛尼下半季爆發成關鍵 與阿古路一同下半季發力的，不是倒戈利..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mapping labels to index\n",
    "class_mapping = {label: idx for idx, label in enumerate(np.unique(df.tags))}\n",
    "inv_class_mapping = {v: k for k, v in class_mapping.items()}\n",
    "df.tags = df.tags.map(class_mapping)\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning text data to remove HTML markup (</a>), emoticons and so on\n",
    "import re\n",
    "# Here I utilized the recommened Chinese word tokenization package jieba to do the word segmentation\n",
    "import jieba\n",
    "def tokenizer(text):\n",
    "    text = re.sub('<[^>]*>', '', text) # remove HTML markup\n",
    "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', text) # find emoticons\n",
    "    text = re.sub('[\\W]+', ' ', text) + ''.join(emoticons).replace('-', '') # add emoticons to the end\n",
    "    tokenized = [w for w in jieba.lcut(text, cut_all=False)]\n",
    "    return tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /var/folders/34/h2dy2w_52v791hl1m4wrsft40000gn/T/jieba.cache\n",
      "Loading model cost 0.989 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['你', ' ', '今天', ' ', '很漂亮', ' ', ':', ')', ':', '(', ':', ')']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing the cleaning tokenizer\n",
    "tokenizer(\"</a>你 :) 今天 :( 很漂亮:-)!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_docs(df):\n",
    "    for a in range(0, len(df.text)):\n",
    "        yield df.text[a:a+1].values.tolist()[0], df.tags[a:a+1].values.tolist()[0]\n",
    "        \n",
    "def get_minibatch(doc_stream, size):\n",
    "    docs, y = [], []\n",
    "    try:\n",
    "        for _ in range(size):\n",
    "            text, label = next(doc_stream)\n",
    "            docs.append(text)\n",
    "            y.append(label)\n",
    "    except StopIteration:\n",
    "            return None, None\n",
    "    return docs, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('利物浦重賽擊敗乙組仔\\u3000英足盃過關 英格蘭足總盃第三圈今晨重賽，貴為英超勁旅的利物浦上場被乙組仔埃克斯特尷尬逼和，多獲一次機會的紅軍不敢再有差池。先有近期回勇的「威爾斯沙維」祖阿倫10分鐘開紀錄，加上兩個小將舒爾奧祖，及祖奧迪西拿下半場各入一球，以3比0擊敗對手，總算在主場挽 <p style=\"text-align: justify;\">英格蘭足總盃第三圈今晨重賽，貴為英超勁旅的利物浦上場被乙組仔埃克斯特尷尬逼和，多獲一次機會的紅軍不敢再有差池。先有近期回勇的「威爾斯沙維」祖阿倫10分鐘開紀錄，加上兩個小將舒爾奧祖，及祖奧迪西拿下半場各入一球，以3比0擊敗對手，總算在主場挽回面子，下一圈對手為韋斯咸。</p> <p style=\"text-align: justify;\">另一場英超球隊對壘，今季異軍突起的李斯特城戰至第三圈就宣告畢業。熱刺憑韓國前鋒孫興<U+615C>上半場遠射破網先開紀錄，換邊後此子助攻予中場查迪尼建功，令球隊以兩球輕取李斯特城，第四圈將面對英甲的高車士打。</p>',\n",
       " 2)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To verify our stream_docs function works correctly\n",
    "next(stream_docs(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "vect = HashingVectorizer(decode_error='ignore',\n",
    "                        n_features=2**21,\n",
    "                        preprocessor=None,\n",
    "                        tokenizer=tokenizer)\n",
    "clf = SGDClassifier(loss='log', random_state=1, max_iter=1)\n",
    "doc_stream = stream_docs(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [##############################] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:33\n"
     ]
    }
   ],
   "source": [
    "# Start the learning progress. Train the model using totally 3000 samples from the training set\n",
    "import pyprind\n",
    "pbar = pyprind.ProgBar(30)\n",
    "classes = np.array([0, 1, 2])\n",
    "for _ in range(30):\n",
    "    X_train, y_train = get_minibatch(doc_stream, size=100)\n",
    "    if not X_train:\n",
    "        break\n",
    "    X_train = vect.transform(X_train)\n",
    "    clf.partial_fit(X_train, y_train, classes=classes)\n",
    "    pbar.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.000\n"
     ]
    }
   ],
   "source": [
    "# Using next 500 samples from the training set to test the model\n",
    "X_test, y_test = get_minibatch(doc_stream, size=1)\n",
    "X_test = vect.transform(X_test)\n",
    "print('Accuracy: %.3f' % clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['【歐聯】曼城反負摩納哥\\u3000防線形同虛設\\u3000哥帥首16強止步（有片） 摩納哥收復首回合落後3︰5的劣勢，主場以3︰1挫曼城，總比數6︰6打和憑作客入球優惠晉級8強，這也是曼城主帥哥迪奧拿執教生涯首次於歐聯16強止步。 需要最少入兩球才有機會晉級的摩納哥未有起用法卡奧或摩天奴擔正，一班年輕新星甫開賽便極之進取，8分鐘貝拿度施華左路傳中，由突破越位的基利安洛天射入近3場第4球。左路成為曼城死症，29分鐘班捷文文迪再於類似位置傳中，通天老倌法賓奴泰華利斯撞射入 <p style=\"text-align: justify;\">需要最少入兩球才有機會晉級的摩納哥未有起用法卡奧或摩天奴擔正，一班年輕新星甫開賽便極之進取，8分鐘貝拿度施華左路傳中，由突破越位的基利安洛天射入近3場第4球。左路成為曼城死症，29分鐘班捷文文迪再於類似位置傳中，通天老倌法賓奴泰華利斯撞射入網，令摩納哥在總比數追成5︰5，若保持賽果至完場將晉級。</p>\\r\\r\\n\\r\\r\\n<p style=\"text-align: justify;\"><strong>曼城右閘位成漏洞</strong></p>\\r\\r\\n\\r\\r\\n<p style=\"text-align: justify;\">上半場起腳未嘗中框的曼城下半場略有改善，前鋒阿古路多次近門機會但都未能轉化為入球，至71分鐘終憑利萊辛尼執死雞，再次在總比數領前。可是曼城防守再次走漏人，被摩納哥的泰莫爾巴卡約高接應罰球頂入。曼城換入前鋒伊恩拿祖仍無力再入球，令李斯特城成為8強唯一英格蘭球會。</p> <p style=\"text-align: justify;\"><strong>李斯特城成8強唯一英格蘭代表</strong></p>\\r\\r\\n\\r\\r\\n<p style=\"text-align: justify;\">首次16強出局的哥迪奧拿認為死因是開局太差以及死球是致命傷︰「下半場做得很好，但上半場則忘記了。我們未能踢出應有水平，要好好學習，始終這支球隊欠缺經驗。出局是因為下半場有機會但未能把握。」摩納哥主帥渣甸則認為晉級實至名歸︰「我們防線壓前，前場表現也很好。下半場對手適應了，以兩個前鋒施壓才能減少曼城控球機會。」歐聯8強抽籤將在3月17日（周五）晚上舉行。</p>'] 足球\n",
      "------------------------------\n",
      "Prediction: 足球\n",
      "Probability: 95.89%\n"
     ]
    }
   ],
   "source": [
    "# See the result of remaining training data one by one. You can run this multiply times\n",
    "X_test, y_test = get_minibatch(doc_stream, size=1)\n",
    "print(X_test, inv_class_mapping[y_test[0]])\n",
    "print('-'*30)\n",
    "X = vect.transform(X_test)\n",
    "label = inv_class_mapping\n",
    "print('Prediction: %s\\nProbability: %.2f%%' % (inv_class_mapping[clf.predict(X)[0]], np.max(clf.predict_proba(X))*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# See results from testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('./offsite-test-material/offsite-tagging-test-set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>969</th>\n",
       "      <td>93507</td>\n",
       "      <td>【熱刺訪港】普捷天奴成搶手貨　主席利維開腔派定心丸 英超今季群雄割據，摩連奴、干地及哥迪奧拿...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970</th>\n",
       "      <td>93651</td>\n",
       "      <td>【熱刺訪港】孫興&lt;U+615C&gt;林志堅再聚舊　承諾賽後交換球衣 熱刺周五將與傑志於香港大球場...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>93690</td>\n",
       "      <td>【港足日與夜．王振鵬】膠唔會膠一世　神經刀變神龍（有片） 有些球員出道十多年，一直都被人睇低...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>93985</td>\n",
       "      <td>【中超】泰維斯抱怨遭中超球員踢傷　澄清無意離開上海申花 受人錢財不一定替人消災，阿根廷前鋒泰...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>94324</td>\n",
       "      <td>【傑志對熱刺．來稿】睇波睇到開party咁先至過癮 剛過去的周末，香港刮起一股足球熱。先是上...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text\n",
       "969  93507  【熱刺訪港】普捷天奴成搶手貨　主席利維開腔派定心丸 英超今季群雄割據，摩連奴、干地及哥迪奧拿...\n",
       "970  93651  【熱刺訪港】孫興<U+615C>林志堅再聚舊　承諾賽後交換球衣 熱刺周五將與傑志於香港大球場...\n",
       "971  93690  【港足日與夜．王振鵬】膠唔會膠一世　神經刀變神龍（有片） 有些球員出道十多年，一直都被人睇低...\n",
       "972  93985  【中超】泰維斯抱怨遭中超球員踢傷　澄清無意離開上海申花 受人錢財不一定替人消災，阿根廷前鋒泰...\n",
       "973  94324  【傑志對熱刺．來稿】睇波睇到開party咁先至過癮 剛過去的周末，香港刮起一股足球熱。先是上..."
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See some example of data\n",
    "df_test.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My predicted tags for the test set:\n",
      "['足球', '梁振英', '足球', '足球', '梁振英', '梁振英', '梁振英', '足球', '足球', '足球', '足球', '足球', '足球', '足球', '足球', '足球', '足球', '梁振英', '梁振英', '梁振英', '美國大選', '梁振英', '梁振英', '梁振英', '梁振英', '梁振英', '足球', '梁振英', '足球', '梁振英', '足球', '梁振英', '足球', '足球', '足球', '足球', '梁振英', '美國大選', '足球', '美國大選', '足球', '梁振英', '足球', '足球', '足球', '足球', '足球', '足球', '足球', '足球', '足球', '美國大選', '足球', '足球', '美國大選', '足球', '足球', '足球', '足球', '足球', '足球', '美國大選', '美國大選', '美國大選', '美國大選', '足球', '足球', '美國大選', '足球', '足球', '足球', '足球', '足球', '梁振英', '足球', '足球', '足球', '足球', '足球', '足球', '足球', '美國大選', '梁振英', '美國大選', '美國大選', '美國大選', '足球', '梁振英', '足球', '足球', '足球', '美國大選', '梁振英', '足球', '足球', '足球', '足球', '足球', '足球', '足球', '美國大選', '足球', '足球', '足球', '足球', '梁振英', '足球', '足球', '足球', '梁振英', '美國大選', '梁振英', '足球', '足球', '足球', '梁振英', '梁振英', '美國大選', '美國大選', '美國大選', '美國大選', '足球', '足球', '美國大選', '梁振英', '美國大選', '梁振英', '美國大選', '足球', '足球', '足球', '足球', '足球', '足球', '足球', '足球', '足球', '足球', '足球', '足球', '足球', '足球', '美國大選', '美國大選', '美國大選', '足球', '足球', '足球', '梁振英', '足球', '足球', '足球', '足球', '足球', '足球', '梁振英', '足球', '美國大選', '足球', '美國大選', '足球', '足球', '足球', '足球', '足球', '足球', '足球', '足球', '足球', '梁振英', '足球', '足球', '足球', '梁振英', '美國大選', '梁振英', '梁振英', '梁振英', '梁振英', '足球', '足球', '梁振英', '梁振英', '足球', '美國大選', '梁振英', '足球', '梁振英', '足球', '梁振英', '梁振英', '足球', '足球', '梁振英', '足球', '足球', '足球', '梁振英', '梁振英', '足球', '足球', '梁振英', '梁振英', '梁振英', '梁振英', '梁振英', '足球', '梁振英', '梁振英', '梁振英', '美國大選', '足球', '美國大選', '美國大選', '足球', '足球', '美國大選', '梁振英', '足球', '足球', '足球', '足球', '梁振英', '足球', '足球', '足球', '足球', '足球', '美國大選', '美國大選', '美國大選', '美國大選', '足球', '足球', '足球', '足球', '梁振英', '足球', '足球', '足球', '梁振英', '美國大選', '梁振英', '足球', '足球', '足球', '足球', '足球', '足球', '足球', '足球', '美國大選', '美國大選', '足球', '足球', '梁振英', '梁振英', '梁振英', '梁振英', '足球', '足球', '梁振英', '梁振英', '梁振英', '足球', '梁振英', '美國大選', '足球', '足球', '足球', '足球', '足球', '美國大選', '美國大選', '足球', '足球', '梁振英', '梁振英', '足球', '梁振英', '足球', '梁振英', '足球', '梁振英', '梁振英', '美國大選', '梁振英', '足球', '足球', '梁振英', '美國大選', '梁振英', '足球', '足球', '足球', '美國大選', '足球', '美國大選', '梁振英', '梁振英', '梁振英', '美國大選', '梁振英', '梁振英', '足球', '美國大選', '足球', '梁振英', '足球', '足球', '足球', '足球', '梁振英', '足球', '足球', '足球', '足球', '足球', '足球', '足球', '足球', '足球', '美國大選', '足球', '足球', '足球', '足球', '足球', '足球', '足球', '足球', '足球', '足球', '足球', '足球', '足球', '足球', '足球', '梁振英', '梁振英', '梁振英', '足球', '足球', '足球', '足球', '足球', '梁振英', '足球', '足球', '足球', '足球', '足球', '梁振英', '足球', '足球', '梁振英', '足球', '足球', '美國大選', '梁振英', '足球', '足球', '梁振英', '梁振英', '梁振英', '梁振英', '足球', '足球', '足球', '足球', '足球', '足球', '足球', '足球', '梁振英', '梁振英', '梁振英', '足球', '梁振英', '足球', '足球', '足球', '足球', '足球', '足球', '足球', '足球', '美國大選', '足球', '美國大選', '足球', '美國大選', '美國大選', '足球', '足球', '足球', '足球', '足球', '美國大選', '足球', '美國大選', '足球', '梁振英', '梁振英', '足球', '足球', '足球', '美國大選', '足球', '美國大選', '足球', '梁振英', '梁振英', '美國大選', '足球', '足球', '足球', '梁振英', '美國大選', '足球', '足球', '足球', '美國大選', '足球', '足球', '足球', '梁振英', '梁振英', '足球', '足球', '足球', '足球', '足球', '足球', '美國大選', '足球', '足球', '梁振英', '梁振英', '梁振英', '梁振英', '梁振英', '足球', '足球', '足球', '美國大選', '梁振英', '足球', '梁振英', '美國大選', '足球', '足球', '美國大選', '美國大選', '美國大選', '梁振英', '足球', '梁振英', '美國大選', '梁振英', '梁振英', '梁振英', '美國大選', '梁振英', '梁振英', '梁振英', '美國大選', '足球', '足球', '美國大選', '梁振英', '美國大選', '美國大選', '美國大選', '梁振英', '美國大選', '美國大選', '梁振英', '美國大選', '美國大選', '足球', '梁振英', '美國大選', '美國大選', '足球', '梁振英', '美國大選', '美國大選', '美國大選', '足球', '美國大選', '美國大選', '足球', '足球', '足球', '美國大選', '美國大選', '美國大選', '足球', '足球', '足球', '足球', '足球', '足球', '足球', '美國大選', '梁振英', '梁振英', '美國大選', '足球', '梁振英', '美國大選', '美國大選', '美國大選', '梁振英', '梁振英', '足球', '足球', '梁振英', '足球', '美國大選', '美國大選', '足球', '梁振英', '足球', '美國大選', '足球', '美國大選', '梁振英', '足球', '美國大選', '梁振英', '足球', '足球', '美國大選', '美國大選', '足球', '足球', '美國大選', '足球', '美國大選', '足球', '梁振英', '足球', '足球', '美國大選', '美國大選', '美國大選', '美國大選', '美國大選', '足球', '美國大選', '美國大選', '梁振英', '美國大選', '美國大選', '美國大選', '足球', '美國大選', '美國大選', '美國大選', '美國大選', '美國大選', '美國大選', '梁振英', '梁振英', '美國大選', '美國大選', '足球', '美國大選', '美國大選', '美國大選', '足球', '梁振英', '梁振英', '美國大選', '美國大選', '梁振英', '梁振英', '梁振英', '美國大選', '足球', '足球', '美國大選', '足球', '梁振英', '足球', '梁振英', '梁振英', '足球', '美國大選', '美國大選', '美國大選', '美國大選', '美國大選', '足球', '美國大選', '足球', '梁振英', '足球', '美國大選', '美國大選', '美國大選', '梁振英', '梁振英', '美國大選', '美國大選', '美國大選', '梁振英', '美國大選', '美國大選', '美國大選', '美國大選', '足球', '梁振英', '美國大選', '美國大選', '美國大選', '美國大選', '美國大選', '足球', '足球', '美國大選', '梁振英', '足球', '美國大選', '美國大選', '美國大選', '美國大選', '美國大選', '足球', '美國大選', '美國大選', '美國大選', '美國大選', '美國大選', '美國大選', '美國大選', '美國大選', '足球', '美國大選', '梁振英', '美國大選', '足球', '美國大選', '美國大選', '美國大選', '美國大選', '美國大選', '足球', '美國大選', '美國大選', '美國大選', '美國大選', '美國大選', '美國大選', '美國大選', '美國大選', '美國大選', '美國大選', '足球', '美國大選', '足球', '美國大選', '足球', '足球', '足球', '足球', '美國大選', '美國大選', '足球', '美國大選', '美國大選', '足球', '梁振英', '梁振英', '足球', '足球', '足球', '美國大選', '足球', '足球', '梁振英', '美國大選', '足球', '足球', '梁振英', '梁振英', '足球', '足球', '梁振英', '足球', '足球', '足球', '足球', '足球', '梁振英', '美國大選', '足球', '足球', '足球', '足球', '梁振英', '梁振英', '梁振英', '足球', '足球', '足球', '梁振英', '梁振英', '梁振英', '足球', '足球', '梁振英', '梁振英', '梁振英', '梁振英', '梁振英', '美國大選', '梁振英', '梁振英', '梁振英', '梁振英', '足球', '足球', '足球', '梁振英', '梁振英', '足球', '梁振英', '梁振英', '足球', '足球', '足球', '梁振英', '足球', '美國大選', '梁振英', '梁振英', '美國大選', '梁振英', '梁振英', '足球', '足球', '梁振英', '梁振英', '足球', '梁振英', '梁振英', '足球', '足球', '梁振英', '足球', '足球', '足球', '梁振英', '足球', '梁振英', '美國大選', '足球', '足球', '足球', '足球', '足球', '足球', '足球', '足球', '美國大選', '美國大選', '梁振英', '足球', '美國大選', '梁振英', '梁振英', '足球', '足球', '足球', '足球', '足球', '梁振英', '梁振英', '足球', '足球', '梁振英', '足球', '美國大選', '足球', '足球', '足球', '梁振英', '足球', '足球', '足球', '足球', '美國大選', '梁振英', '足球', '足球', '梁振英', '足球', '足球', '足球', '足球', '足球', '足球', '足球', '梁振英', '足球', '足球', '足球', '足球', '足球', '足球', '足球', '足球', '足球', '足球', '足球', '足球', '足球', '足球', '足球', '足球', '梁振英', '足球', '足球', '足球', '足球', '足球', '足球', '足球', '足球', '梁振英', '梁振英', '足球', '足球', '足球', '梁振英', '足球', '足球', '足球', '梁振英', '足球', '足球', '足球', '足球', '梁振英', '足球', '足球', '足球', '足球', '梁振英', '足球', '梁振英', '梁振英', '足球', '足球', '足球', '足球', '足球', '足球', '足球', '足球', '足球', '足球', '足球', '足球', '足球', '足球', '梁振英', '足球', '足球', '足球', '足球', '足球', '足球', '足球', '足球', '足球', '足球', '足球', '足球', '足球', '足球', '足球', '足球', '足球', '足球', '足球', '足球', '足球', '足球', '足球', '足球', '足球', '梁振英', '梁振英', '足球', '梁振英', '足球', '足球', '梁振英', '足球', '足球', '足球', '足球', '足球', '足球', '梁振英', '梁振英', '足球', '梁振英', '足球', '梁振英', '梁振英', '梁振英', '梁振英', '足球', '足球', '足球', '足球', '足球', '足球', '梁振英', '足球', '足球', '足球', '梁振英', '足球', '足球', '足球', '足球', '足球', '足球', '足球', '足球', '梁振英', '足球', '足球', '足球', '梁振英', '足球', '梁振英', '足球', '梁振英', '足球', '梁振英', '足球', '梁振英', '足球', '梁振英', '足球', '梁振英', '足球', '足球', '足球', '梁振英', '梁振英', '足球', '足球', '梁振英', '足球', '足球', '足球', '梁振英', '足球', '梁振英', '足球', '梁振英', '足球', '足球', '足球', '足球', '足球']\n"
     ]
    }
   ],
   "source": [
    "X = vect.transform(df_test.text)\n",
    "label = inv_class_mapping\n",
    "y = []\n",
    "for i in range(X.shape[0]):\n",
    "    y.append(label[clf.predict(X[i])[0]])   \n",
    "print('My predicted tags for the test set:')\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add tags column to dataframe\n",
    "df_test.insert(loc=1, column='tags', value=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(df_test).to_csv('./offsite-test-set-with-tags.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tags</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>969</th>\n",
       "      <td>93507</td>\n",
       "      <td>足球</td>\n",
       "      <td>【熱刺訪港】普捷天奴成搶手貨　主席利維開腔派定心丸 英超今季群雄割據，摩連奴、干地及哥迪奧拿...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970</th>\n",
       "      <td>93651</td>\n",
       "      <td>足球</td>\n",
       "      <td>【熱刺訪港】孫興&lt;U+615C&gt;林志堅再聚舊　承諾賽後交換球衣 熱刺周五將與傑志於香港大球場...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>93690</td>\n",
       "      <td>足球</td>\n",
       "      <td>【港足日與夜．王振鵬】膠唔會膠一世　神經刀變神龍（有片） 有些球員出道十多年，一直都被人睇低...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>93985</td>\n",
       "      <td>足球</td>\n",
       "      <td>【中超】泰維斯抱怨遭中超球員踢傷　澄清無意離開上海申花 受人錢財不一定替人消災，阿根廷前鋒泰...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>94324</td>\n",
       "      <td>足球</td>\n",
       "      <td>【傑志對熱刺．來稿】睇波睇到開party咁先至過癮 剛過去的周末，香港刮起一股足球熱。先是上...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id tags                                               text\n",
       "969  93507   足球  【熱刺訪港】普捷天奴成搶手貨　主席利維開腔派定心丸 英超今季群雄割據，摩連奴、干地及哥迪奧拿...\n",
       "970  93651   足球  【熱刺訪港】孫興<U+615C>林志堅再聚舊　承諾賽後交換球衣 熱刺周五將與傑志於香港大球場...\n",
       "971  93690   足球  【港足日與夜．王振鵬】膠唔會膠一世　神經刀變神龍（有片） 有些球員出道十多年，一直都被人睇低...\n",
       "972  93985   足球  【中超】泰維斯抱怨遭中超球員踢傷　澄清無意離開上海申花 受人錢財不一定替人消災，阿根廷前鋒泰...\n",
       "973  94324   足球  【傑志對熱刺．來稿】睇波睇到開party咁先至過癮 剛過去的周末，香港刮起一股足球熱。先是上..."
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./offsite-test-set-with-tags.csv')\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1: How well does your model perform\n",
    "## Answer:\n",
    "I use 3000 samples from the training set to train my model and 500 samples from the training set to test. I got 98%-100% accuracy when I train it several times. Below is the code for my model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Question 2: How did you choose the parameters of the final model\n",
    "## Answer:\n",
    "I did not quite get this question. The model was trained by SGD (stochastic gradient descent) and the parameters was were updated through the training process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3: On a high level, please explain your final model’s structure, and how it predicts tags from the article text\n",
    "## Answer:\n",
    "In fact, I used the traditional **logistic regression model** for this new classification since the task is quite simple. After loading the data from the csv file, the first important step is to clean the text data by stripping it of all unwanted characters, for example HTML markup or punctuation. Then I process the text into tokens with **jieba**. After that, I vectorizer the text using **HashingVectorizer** from *scikit-learn*. Having set up all the complementary functions, I can start to train the logistic regression model with stochastic gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
